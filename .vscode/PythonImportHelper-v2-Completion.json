[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "importlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib",
        "description": "importlib",
        "detail": "importlib",
        "documentation": {}
    },
    {
        "label": "CYCLES",
        "importPath": "classes",
        "description": "classes",
        "isExtraImport": true,
        "detail": "classes",
        "documentation": {}
    },
    {
        "label": "Links",
        "importPath": "classes.CONSTANTS",
        "description": "classes.CONSTANTS",
        "isExtraImport": true,
        "detail": "classes.CONSTANTS",
        "documentation": {}
    },
    {
        "label": "ZoneInfo",
        "importPath": "zoneinfo",
        "description": "zoneinfo",
        "isExtraImport": true,
        "detail": "zoneinfo",
        "documentation": {}
    },
    {
        "label": "webdriver",
        "importPath": "selenium",
        "description": "selenium",
        "isExtraImport": true,
        "detail": "selenium",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "By",
        "importPath": "selenium.webdriver.common.by",
        "description": "selenium.webdriver.common.by",
        "isExtraImport": true,
        "detail": "selenium.webdriver.common.by",
        "documentation": {}
    },
    {
        "label": "Keys",
        "importPath": "selenium.webdriver.common.keys",
        "description": "selenium.webdriver.common.keys",
        "isExtraImport": true,
        "detail": "selenium.webdriver.common.keys",
        "documentation": {}
    },
    {
        "label": "Options",
        "importPath": "selenium.webdriver.chrome.options",
        "description": "selenium.webdriver.chrome.options",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.options",
        "documentation": {}
    },
    {
        "label": "Service",
        "importPath": "selenium.webdriver.chrome.service",
        "description": "selenium.webdriver.chrome.service",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.service",
        "documentation": {}
    },
    {
        "label": "WebDriverWait",
        "importPath": "selenium.webdriver.support.ui",
        "description": "selenium.webdriver.support.ui",
        "isExtraImport": true,
        "detail": "selenium.webdriver.support.ui",
        "documentation": {}
    },
    {
        "label": "ChromeDriverManager",
        "importPath": "webdriver_manager.chrome",
        "description": "webdriver_manager.chrome",
        "isExtraImport": true,
        "detail": "webdriver_manager.chrome",
        "documentation": {}
    },
    {
        "label": "expected_conditions",
        "importPath": "selenium.webdriver.support",
        "description": "selenium.webdriver.support",
        "isExtraImport": true,
        "detail": "selenium.webdriver.support",
        "documentation": {}
    },
    {
        "label": "ResponsesSPCAPITAL",
        "importPath": "classes.CYCLES.SP_CAPITAL.SP_CAPITAL",
        "description": "classes.CYCLES.SP_CAPITAL.SP_CAPITAL",
        "isExtraImport": true,
        "detail": "classes.CYCLES.SP_CAPITAL.SP_CAPITAL",
        "documentation": {}
    },
    {
        "label": "check_status",
        "importPath": "AUTHORIZATION",
        "description": "AUTHORIZATION",
        "isExtraImport": true,
        "detail": "AUTHORIZATION",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "init_driver",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def init_driver():\n    download_dir = os.path.join(os.getcwd(), \"downloads\")\n    os.makedirs(download_dir, exist_ok=True)\n    chrome_options = Options()\n    chrome_options.add_argument(\"--no-sandbox\")\n    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n    if not os.getenv(\"GITHUB_ACTIONS\"):\n        temp_user_data_dir = tempfile.mkdtemp()\n        chrome_options.add_argument(f\"user-data-dir={temp_user_data_dir}\")\n    else:",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "waitFunc",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def waitFunc(timeWait=30):\n    return WebDriverWait(driver, timeWait)\ndef wait_element(css_selector=\".div-loader\", timeWait=30):\n    print(\"âŒ› Waiting for element:\", css_selector)\n    wait = waitFunc(timeWait)\n    try:\n        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, css_selector)))\n        print(\"âœ… Element found!\")\n        wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, css_selector)))\n        print(\"âœ… Element invisible!\")",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "wait_element",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def wait_element(css_selector=\".div-loader\", timeWait=30):\n    print(\"âŒ› Waiting for element:\", css_selector)\n    wait = waitFunc(timeWait)\n    try:\n        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, css_selector)))\n        print(\"âœ… Element found!\")\n        wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, css_selector)))\n        print(\"âœ… Element invisible!\")\n        return True\n    except Exception as e:",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "find_element_by_css",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def find_element_by_css(css_selector):\n    return driver.find_element(By.CSS_SELECTOR, css_selector)\ndef verify_hour():\n    now = datetime.now(ZoneInfo(\"America/Sao_Paulo\"))\n    start = now.replace(hour=7, minute=30, second=0, microsecond=0)\n    end = now.replace(hour=9, minute=0, second=0, microsecond=0)\n    if start < now < end:\n        print(\"HorÃ¡rio entre 7:30 e 9:00 detectado. Encerrando a execuÃ§Ã£o do script.\")\n        exit(0)\ndef access_page(url):",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "verify_hour",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def verify_hour():\n    now = datetime.now(ZoneInfo(\"America/Sao_Paulo\"))\n    start = now.replace(hour=7, minute=30, second=0, microsecond=0)\n    end = now.replace(hour=9, minute=0, second=0, microsecond=0)\n    if start < now < end:\n        print(\"HorÃ¡rio entre 7:30 e 9:00 detectado. Encerrando a execuÃ§Ã£o do script.\")\n        exit(0)\ndef access_page(url):\n    driver.get(url)\n    print(f\"ðŸ”¹ Accessing page: {url}\")",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "access_page",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def access_page(url):\n    driver.get(url)\n    print(f\"ðŸ”¹ Accessing page: {url}\")\n    print(f\"ðŸ“„ Page title: {driver.title}\")\n    wait_element(\".flex.items-center.justify-center.fixed.z-50.bg-gray-200.h-screen.w-screen.inset-0.ng-tns-c98-0.ng-star-inserted\")\n    print(\"âœ… Page loaded!\")\ndef fill_login_form():\n    wait = waitFunc()\n    login_input = find_element_by_css(\"input.flex.border.appearance-none.leading-tight\")\n    login_button = find_element_by_css(\"button.flex.justify-center.items-center.cursor-pointer\")",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "fill_login_form",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def fill_login_form():\n    wait = waitFunc()\n    login_input = find_element_by_css(\"input.flex.border.appearance-none.leading-tight\")\n    login_button = find_element_by_css(\"button.flex.justify-center.items-center.cursor-pointer\")\n    login_input.send_keys(EMAIL)\n    login_button.click()\n    wait_element()\n    password_input = find_element_by_css(\"input.flex.border.appearance-none.leading-tight.w-full.pl-10.pr-4.pr-8.h-10.text-xs.border-gray-400.text-gray-800.rounded\")\n    password_input.click()\n    time.sleep(.5)",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "data_listing_page",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def data_listing_page():\n    time.sleep(1)\n    wait_element(\".block-page-div-loader\")\n    print(\"âœ… Page loaded!\")\n    time.sleep(1)\n    wait_element(\".block-page-div-loader\")\n    time.sleep(1)\n    print(\"âœ… Data loaded!\")\n    wait_element(\".ngt-shining-xs\")\n    print(\"âœ… ConteÃºdo carregado!\")",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "get_available_cycle",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def get_available_cycle(skip_cycle=None):\n    global LAST_CYCLE\n    cycles_path = CYCLES.__path__[0]\n    for cycle_folder in os.listdir(cycles_path):\n        folder_path = os.path.join(cycles_path, cycle_folder)\n        if os.path.isdir(folder_path):\n            cycle_file = os.path.join(folder_path, f\"{cycle_folder}.py\")\n            if os.path.exists(cycle_file):\n                spec = importlib.util.spec_from_file_location(cycle_folder, cycle_file)\n                module = importlib.util.module_from_spec(spec)",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "select_cycle",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def select_cycle(cycle_text):\n    wait = waitFunc()\n    xpath = f\"//div[contains(@class, 'scrollable-content')]//div[contains(normalize-space(.), '{cycle_text}')]\"\n    try:\n        element = wait.until(EC.element_to_be_clickable((By.XPATH, xpath)))\n        print(f\"âœ… Ciclo encontrado: {element.text}\")\n        element.click()\n    except Exception as e:\n        print(f\"âŒ Erro: nÃ£o foi possÃ­vel encontrar ou clicar no ciclo '{cycle_text}'.\")\n        raise e",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "filter_pending_reports",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def filter_pending_reports(secund_page=False):\n    global LAST_CYCLE\n    wait = waitFunc()\n    try:\n        parent_xpath = \"(//div[contains(@class, 'float-right ml-2 ng-star-inserted')])[2]\"\n        link_xpath = f\"{parent_xpath}//a[contains(@class, 'cursor-pointer ng-star-inserted')]\"\n        filter_button = wait.until(EC.element_to_be_clickable((By.XPATH, link_xpath)))\n        print(\"âœ… Link encontrado.\")\n        filter_button.click()\n        print(\"âœ… Clicado no link encontrado.\")",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "generate_random_date",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def generate_random_date():\n    start_date = datetime(2024, 1, 1)\n    end_date = datetime(2024, 12, 31)\n    delta = end_date - start_date\n    random_days = random.randint(0, delta.days)\n    random_date = start_date + timedelta(days=random_days)\n    return random_date.strftime('%d/%m/%Y')\ndef fill_form(cycle):\n    print(\"Passo 1: Iniciando preenchimento do formulÃ¡rio\")\n    wait_element(\".ngt-shining-xs\")",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "fill_form",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def fill_form(cycle):\n    print(\"Passo 1: Iniciando preenchimento do formulÃ¡rio\")\n    wait_element(\".ngt-shining-xs\")\n    wait = waitFunc()\n    def click_input_field(index, tab=False):\n        input_fields = driver.find_elements(By.CSS_SELECTOR, \"div.ng-input > input\")\n        if input_fields and index < len(input_fields):\n            driver.execute_script(\"arguments[0].scrollIntoView(true);\", input_fields[index])\n            time.sleep(0.5)\n            input_fields[index].click()",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "close_pending_issues",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def close_pending_issues(rows, cycle):\n    print(\"âš ï¸ There are pending issues! Starting the process to close them...\")\n    try:\n        pending_row = None\n        for row in rows:\n            try:\n                status_badge = row.find_element(By.XPATH, \".//div[contains(text(),'Pendente')]\")\n                if \"PENDENTE\" in status_badge.text.strip().upper():\n                    pending_row = row\n                    break",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "check_pgrs_pending",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def check_pgrs_pending():\n    time.sleep(1)\n    tbody = driver.find_element(By.CSS_SELECTOR, \"tbody.bg-white\")\n    rows = tbody.find_elements(By.TAG_NAME, \"tr\")\n    pending_count = 0\n    non_pending_count = 0\n    for row in rows:\n        try:\n            status_badge = row.find_element(By.XPATH, \".//div[contains(text(),'Pendente')]\")\n            if \"PENDENTE\" in status_badge.text.strip().upper():",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "navigate_pages_until_pending",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def navigate_pages_until_pending(cycle, secund_page=False):\n    if secund_page:\n        try:\n            wait_element(\".ngx-toastr.toast-info\", 60)\n            wait_element(\".block-page-div-loader\", 3)\n        except:\n            pass\n        pending_count, rows = check_pgrs_pending()\n        if pending_count < 1:\n            filter_pending_reports(secund_page=True)",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "run_bot",
        "kind": 2,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "def run_bot():\n    print(\"ðŸ”¹ Starting BOT_CEF...\")\n    url = Links.url\n    try:\n        access_page(url)\n        fill_login_form()\n        data_listing_page()\n        filter_pending_reports()\n    finally:\n        driver.quit()",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "EMAIL",
        "kind": 5,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "EMAIL = os.getenv(\"EMAIL\")\nPASSWORD = os.getenv(\"PASSWORD\")\nLAST_CYCLE = None\nFILLING_AMOUNT = 0\ndriver = init_driver()\ndef waitFunc(timeWait=30):\n    return WebDriverWait(driver, timeWait)\ndef wait_element(css_selector=\".div-loader\", timeWait=30):\n    print(\"âŒ› Waiting for element:\", css_selector)\n    wait = waitFunc(timeWait)",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "PASSWORD",
        "kind": 5,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "PASSWORD = os.getenv(\"PASSWORD\")\nLAST_CYCLE = None\nFILLING_AMOUNT = 0\ndriver = init_driver()\ndef waitFunc(timeWait=30):\n    return WebDriverWait(driver, timeWait)\ndef wait_element(css_selector=\".div-loader\", timeWait=30):\n    print(\"âŒ› Waiting for element:\", css_selector)\n    wait = waitFunc(timeWait)\n    try:",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "LAST_CYCLE",
        "kind": 5,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "LAST_CYCLE = None\nFILLING_AMOUNT = 0\ndriver = init_driver()\ndef waitFunc(timeWait=30):\n    return WebDriverWait(driver, timeWait)\ndef wait_element(css_selector=\".div-loader\", timeWait=30):\n    print(\"âŒ› Waiting for element:\", css_selector)\n    wait = waitFunc(timeWait)\n    try:\n        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, css_selector)))",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "FILLING_AMOUNT",
        "kind": 5,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "FILLING_AMOUNT = 0\ndriver = init_driver()\ndef waitFunc(timeWait=30):\n    return WebDriverWait(driver, timeWait)\ndef wait_element(css_selector=\".div-loader\", timeWait=30):\n    print(\"âŒ› Waiting for element:\", css_selector)\n    wait = waitFunc(timeWait)\n    try:\n        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, css_selector)))\n        print(\"âœ… Element found!\")",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "driver",
        "kind": 5,
        "importPath": "bot.scraper",
        "description": "bot.scraper",
        "peekOfCode": "driver = init_driver()\ndef waitFunc(timeWait=30):\n    return WebDriverWait(driver, timeWait)\ndef wait_element(css_selector=\".div-loader\", timeWait=30):\n    print(\"âŒ› Waiting for element:\", css_selector)\n    wait = waitFunc(timeWait)\n    try:\n        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, css_selector)))\n        print(\"âœ… Element found!\")\n        wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, css_selector)))",
        "detail": "bot.scraper",
        "documentation": {}
    },
    {
        "label": "SPCAPITAL",
        "kind": 6,
        "importPath": "classes.CYCLES.SP_CAPITAL.SP_CAPITAL",
        "description": "classes.CYCLES.SP_CAPITAL.SP_CAPITAL",
        "peekOfCode": "class SPCAPITAL:\n    CAN_FILL = True\n    NAME = \"SÃƒO PAULO CAPITAL\"\nclass ResponsesSPCAPITAL(SPCAPITAL):\n    ESTRUTURA_ARMAZENAMENTO = \"Ãrea coberta, ventilada, piso impermeÃ¡vel, contÃ©m o coletor/tambor onde as lÃ¢mpadas sÃ£o armazenadas de forma temporÃ¡ria atÃ© a coleta.\"\n    RESIDUOS_ENCAMINHADOS = \"LÃ¢mpadas\"\n    EMPRESA_RESPONSAVEL = \"EQS ENGENHARIA S.A\"\n    ENDERECO_LOCAL = \"Rua Odete Gomes Barreto, 262 - Vila Nova Manchester SÃ£o Paulo - SP\"\n    RESIDUOS_ARMAZENADOS = \"LÃ¢mpadas\"\n    SUGESTAO_MELHORIA = \"Nenhuma sugestÃ£o de melhoria.\"",
        "detail": "classes.CYCLES.SP_CAPITAL.SP_CAPITAL",
        "documentation": {}
    },
    {
        "label": "ResponsesSPCAPITAL",
        "kind": 6,
        "importPath": "classes.CYCLES.SP_CAPITAL.SP_CAPITAL",
        "description": "classes.CYCLES.SP_CAPITAL.SP_CAPITAL",
        "peekOfCode": "class ResponsesSPCAPITAL(SPCAPITAL):\n    ESTRUTURA_ARMAZENAMENTO = \"Ãrea coberta, ventilada, piso impermeÃ¡vel, contÃ©m o coletor/tambor onde as lÃ¢mpadas sÃ£o armazenadas de forma temporÃ¡ria atÃ© a coleta.\"\n    RESIDUOS_ENCAMINHADOS = \"LÃ¢mpadas\"\n    EMPRESA_RESPONSAVEL = \"EQS ENGENHARIA S.A\"\n    ENDERECO_LOCAL = \"Rua Odete Gomes Barreto, 262 - Vila Nova Manchester SÃ£o Paulo - SP\"\n    RESIDUOS_ARMAZENADOS = \"LÃ¢mpadas\"\n    SUGESTAO_MELHORIA = \"Nenhuma sugestÃ£o de melhoria.\"\n    DIAGNOSTICO_RESIDUOS = \"LÃ¢mpadas\"\n    TRATAMENTO = \"DescontaminaÃ§Ã£o de lÃ¢mpadas\"\n    JUSTIFICATIVA = \"No processo de descontaminaÃ§Ã£o os componentes das lÃ¢mpadas sÃ£o separados para enviÃ¡-los Ã  reciclagem ou viabilizar sua reutilizaÃ§Ã£o.\"",
        "detail": "classes.CYCLES.SP_CAPITAL.SP_CAPITAL",
        "documentation": {}
    },
    {
        "label": "Links",
        "kind": 6,
        "importPath": "classes.CONSTANTS",
        "description": "classes.CONSTANTS",
        "peekOfCode": "class Links:\n    url = \"https://web.eloverde.com.br/\"",
        "detail": "classes.CONSTANTS",
        "documentation": {}
    },
    {
        "label": "check_status",
        "kind": 2,
        "importPath": "AUTHORIZATION",
        "description": "AUTHORIZATION",
        "peekOfCode": "def check_status():\n    url = \"https://raw.githubusercontent.com/m1caelvr/m1caelvr/refs/heads/main/key.txt\"\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n        lines = response.text.strip().split(\"\\n\")\n        config = {}\n        for line in lines:\n            if \"=\" in line:\n                key, value = line.split(\"=\")",
        "detail": "AUTHORIZATION",
        "documentation": {}
    }
]